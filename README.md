# Weather ETL Pipeline

## Project Description
This project implements an end-to-end data engineering pipeline that processes real-world weather data from NOAA's Climate Data Online API. The pipeline ingests daily weather data (e.g., temperature, precipitation) for a selected city, transforms and cleans the data, stores it in a PostgreSQL database, and automates the workflow using Apache Airflow, all containerized with Docker. A Streamlit dashboard provides simple visualizations of the processed data.

Built to demonstrate practical data engineering skills, this project showcases:
- **Data Ingestion**: Fetching data via APIs and handling raw CSV files.
- **Transformation**: Cleaning and aggregating data with Pandas.
- **Storage**: Managing data in a relational database (PostgreSQL).
- **Orchestration**: Automating workflows with Airflow.
- **Containerization**: Ensuring reproducibility with Docker.
- **Monitoring**: Implementing logging for pipeline reliability.

This portfolio piece reflects industry-standard practices, preparing me for data engineering roles by showcasing my ability to design, build, and deploy scalable data pipelines.

## Tech Stack
- **Python**: Requests, Pandas, SQLAlchemy
- **Docker**: Containerization of pipeline components
- **PostgreSQL**: Data storage
- **Apache Airflow**: Workflow orchestration
- **Streamlit**: Visualization dashboard
- **Git**: Version control

## Setup Instructions
(TBD: Detailed setup instructions will be added upon project completion)

## Project Status
In progress, with daily updates as part of a 14-day development plan (started September 24, 2025). See [doc/](doc/) for detailed progress and diagrams.